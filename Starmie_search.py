
import utilities as utl
import pandas as pd
import csv


class Starmie_Search:
# this class is used to do reranking using Starmie 

    def __init__(self):
        """
        :param data_source: The source of the data (e.g., file path, database, etc.).
        :param search_parameters: Dictionary containing parameters for the search (optional).
        """
        self.k=0
        self.results = []
  

    def load_data(self):
        """
        Load data from the specified source.

        The schema for the data is expected as:
        ['query_table_name', 'query_column', 'query_column#', 
        'dl_table_name', 'dl_column#', 'dl_column']

        :return: None
        """
        try:
            # Load the CSV file into a pandas DataFrame
            self.data = pd.read_csv(self.data_source)

            # Verify that the required columns are present
            required_columns = ['query_table_name', 'query_column', 'query_column#',
                                'dl_table_name', 'dl_column#', 'dl_column']
            if not all(column in self.data.columns for column in required_columns):
                missing_columns = [col for col in required_columns if col not in self.data.columns]
                raise ValueError(f"Missing required columns in data: {missing_columns}")

            print("Data loaded successfully")
        
        except FileNotFoundError:
            print(f"Error: File not found at {self.data_source}")
        
        except ValueError as e:
            print(f"Error: {e}")
        
        except Exception as e:
            print(f"An unexpected error occurred: {e}")
    
    def load_unionable_tables(self, path):
        #load the mapping between query and its unionnable tables generated by a system like Starmie
        
         self.unionable_data= utl.loadDictionaryFromPickleFile(path)    
         
         
if __name__ == "__main__":
    # Example usage:


    s_search = Starmie_Search()

    # we load the data corresponindt to acolumn alignment generated by DUST for the output of
    # Starmie on Santos returning maximum 50 unionable dl tables  for each query
    #s_search.load_data()

    #datafolder= "data/table-union-search-benchmark/small"
    datafolder="data/santos/small"
    # evaluate Starmie 50 results at different k 
    # unionable reuslts are loaded here:
    first_20_starmie_with_scores=f"{datafolder}/diveristy_data/search_results/Starmie/top_20_Starmie_output_04diluted_restricted_withscore.pkl"
    s_search.load_unionable_tables(first_20_starmie_with_scores) 
    #ground truth is here  
    #gtruth="data/santos/santosUnionBenchmark.pickle"
    #now convert the format of first_50_starmie_with_scores to gmc result format in csv: query_name, tables, execution time, k
    # here we put zero for all execution time for now 
    # Iterate over the dictionary and sort the values
    sorted_unionable_data = {}
    for query_name, tuples_list in s_search.unionable_data.items():
        # Sort the list of tuples based on the second element
        sorted_list = sorted(tuples_list, key=lambda x: x[1],  reverse=True)
        # Store the sorted list in a new dictionary
        sorted_unionable_data[query_name] = sorted_list    
    starmie_search=f"{datafolder}/diveristy_data/search_results/Starmie/starmie_results_04diluted_restricted.csv"    
    # now for k =2 to 20 create the file 
    # Define the output CSV file path
    output_csv_file = starmie_search
        # Open the CSV file for writing
    with open(output_csv_file, mode="a", newline="") as csv_file:
        # Define the CSV writer
        csv_writer = csv.writer(csv_file)
        
        # Write the header row
        csv_writer.writerow(["query_name", "tables", "execution_time", "k"])
        for k_ in range(2, 11):
        # Iterate over the sorted dictionary
                for query_name, tuples_list in sorted_unionable_data.items():
                    utables=[]
                    for i in range(0, k_):
                        try:
                        # Extract the first value of the tuple
                            utables.append(tuples_list[i][0])
                        except Exception as e:
                            print (str(e)+"for K="+str(k_)+" and query "+ query_name)
                            break
                        # Write the row with k = 0 and time = 0
                    csv_writer.writerow([query_name, utables, 0, k_])